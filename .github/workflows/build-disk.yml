---
name: Build disk images

permissions:
  contents: read
  packages: read

on:
  workflow_dispatch:
    inputs:
      upload-to-s3:
        description: "Upload to S3"
        required: false
        default: false
        type: boolean
      platform:
        description: "Target Arch"
        required: true
        type: choice
        options:
          - amd64
          - arm64
  pull_request:
    branches:
      - main
    paths:
      - './disk_config/disk.toml'
      - './disk_config/iso.toml'
      - './.github/workflows/build-disk.yml'

env:
  IMAGE_NAME: ${{ github.event.repository.name }} # output of build.yml, keep in sync
  IMAGE_REGISTRY: "ghcr.io/${{ github.repository_owner }}"  # do not edit
  DEFAULT_TAG: "latest"
  BIB_IMAGE: "quay.io/centos-bootc/bootc-image-builder:latest" # "quay.io/centos-bootc/bootc-image-builder:latest" - see https://github.com/osbuild/bootc-image-builder/pull/954

concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build:
    name: Build disk images
    runs-on: ${{ inputs.platform == 'amd64' && 'ubuntu-24.04' || 'ubuntu-24.04-arm' }}
    strategy:
      fail-fast: false
      matrix:
        disk-type: ["anaconda-iso"]
        # disk-type: ["qcow2", "anaconda-iso"]
        major_version: [43]
    permissions:
      contents: read
      packages: read
      id-token: write

    steps:
      - name: Prepare environment
        run: |
          USER_UID=$(id -u)
          USER_GID=$(id -g)
          # Concatenate the types with a hyphen
          DISK_TYPE=$(echo "${{ matrix.disk-type }}" | tr ' ' '-')
          # Lowercase the image uri
          echo "IMAGE_REGISTRY=${IMAGE_REGISTRY,,}" >> ${GITHUB_ENV}
          echo "IMAGE_NAME=${IMAGE_NAME,,}" >> ${GITHUB_ENV}
          echo "DISK_TYPE=${DISK_TYPE}" >> ${GITHUB_ENV}
          echo "USER_UID=${USER_UID}" >> ${GITHUB_ENV}
          echo "USER_GID=${USER_GID}" >> ${GITHUB_ENV}

      - name: Install dependencies
        if: inputs.platform == 'arm64'
        run: |
          set -x
          sudo apt update -y
          sudo apt install -y \
            podman

      - name: Maximize build space
        if: inputs.platform != 'arm64'
        uses: ublue-os/remove-unwanted-software@cc0becac701cf642c8f0a6613bbdaf5dc36b259e # v9
        with:
          remove-codeql: true

      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
      
      - name: Login to GitHub Container Registry
        uses: docker/login-action@5e57cd118135c172c3672efd75eb46360885c0ef # v3
        if: github.event_name != 'pull_request' && github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Bazzite Repo
        id: setup-bazzite-repo
        shell: bash
        run: |
          curl -Lo ${{ github.workspace }}/bazzite.repo https://copr.fedorainfracloud.org/coprs/ublue-os/bazzite/repo/fedora-${{ matrix.major_version }}/bazzite-org-bazzite-fedora-${{ matrix.major_version }}.repo

      # Docker requires lowercase registry references
      - name: Lowercase Registry
        id: registry_case
        uses: ASzc/change-string-case-action@d0603cd0a7dd490be678164909f65c7737470a7f # v6
        with:
          string: ${{ env.IMAGE_REGISTRY }}

      - name: Build ISOs
        uses: jasonn3/build-container-installer@c9ef3de33236e66781ec37bd0485e8009eaefe24 # v1.4.0
        id: build
        with:
          arch: x86_64
          image_name: ${{ env.IMAGE_NAME }}
          image_repo: ${{ steps.registry_case.outputs.lowercase }}
          variant: 'KDE'
          version: ${{ matrix.major_version }}
          image_tag: ${{ env.DEFAULT_TAG }}
          secure_boot_key_url: '${{ github.server_url }}/${{ github.repository_owner }}/bazzite/raw/main/secure_boot.der'
          enrollment_password: 'universalblue'
          iso_name: ${{ env.IMAGE_NAME }}-${{ inputs.platform }}.iso
          enable_cache_dnf: "false"
          enable_cache_skopeo: "false"
          # flatpak_remote_refs_dir: ${{ steps.generate-flatpak-dir-shortname.outputs.flatpak-dir-shortname }}
          enable_flatpak_dependencies: "false"
          extra_boot_params: ${{ steps.generate-extra-params.outputs.extra-boot-params }}
          # additional_templates: '/github/workspace/installer/lorax_templates/remove_root_password_prompt.tmpl /github/workspace/installer/lorax_templates/set_default_user.tmpl'
          # repos: '/github/workspace/bazzite.repo /etc/yum.repos.d/fedora.repo /etc/yum.repos.d/fedora-updates.repo'


      # - name: Build disk images
      #   id: build
      #   uses: osbuild/bootc-image-builder-action@main
      #   with:
      #     builder-image: ${{ env.BIB_IMAGE }}
      #     config-file: ${{ matrix.disk-type == 'anaconda-iso' && './disk_config/iso.toml' || './disk_config/disk.toml' }}
      #     image: ${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}
      #     chown: ${{ env.USER_UID }}:${{ env.USER_GID }}
      #     types: ${{ matrix.disk-type }}
      #     additional-args: --use-librepo=True --rootfs btrfs

      - name: Upload disk images and Checksum to Job Artifacts
        if: inputs.upload-to-s3 != true && github.event_name != 'pull_request'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: ${{ env.IMAGE_NAME }}-iso
          path: |
            bazziteos-amd64.iso
            bazziteos-amd64.iso-CHECKSUM
          if-no-files-found: error
          retention-days: 10
          compression-level: 0
      
      - name: Upload to S3
        if: inputs.upload-to-s3 == true && github.event_name != 'pull_request'
        shell: bash
        env:
          RCLONE_CONFIG_S3_TYPE: s3
          RCLONE_CONFIG_S3_PROVIDER: ${{ secrets.S3_PROVIDER }}
          RCLONE_CONFIG_S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          RCLONE_CONFIG_S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          RCLONE_CONFIG_S3_REGION: ${{ secrets.S3_REGION }}
          RCLONE_CONFIG_S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          SOURCE_DIR: ${{ steps.build.outputs.output-directory }}
        run: |
          sudo apt-get update
          sudo apt-get install -y rclone
          rclone copy $SOURCE_DIR S3:${{ secrets.S3_BUCKET_NAME }}
